# **AIエージェントシステム \- 実装に向けた設計方針**

これまでの議論に基づき、本システムのPoC開発における主要な設計方針を以下に定める。

## **1\. 設計方針サマリー**

### **思考ワークフロー**

* **定義:** TypeScriptでハードコードされた、自己完結型の小さな関数。  
* **実行モデル:** 単一のイベントループによるシリアル実行。並列処理は行わない。  
* **トリガー:** Reportersからの情報、ユーザーのリクエスト、他のワークフローからの後続リクエスト。  
* **プログラマビリティ:** ワークフローの連なりと、それに渡す動的なデータを制御することで担保する。

### **State文書**

* **役割:** システム全体で共有される、単一の自然言語による短期的なワーキングメモリ。  
* **更新:** 楽観的ロックを採用。競合は致命的な問題とはしない。  
* **管理:** Stateのサイズを常時監視し、別ワークフローが頻繁に情報をIssue等へ構造化することで肥大化を防ぐ。  
* **構造:** 基本構造はKnowledgeとして定義し、メンテナンス時にそれを参照してAIが自律的に整形する。

### **Modularプロンプトフレームワーク**

* **役割:** ワークフローがLLMにリクエストを送信する際に、独自開発の「Modularプロンプト」フレームワークを利用する。  
* **目的:** 構造化された部品（モジュール）を組み合わせることで、動的なデータに対応しつつも、安定的で高品質なプロンプトの生成を担保する。  
* **実装:** 各ワークフローは、このフレームワークを通じてLLMへの指示を構成する。1つのワークフローが内部で複数回のLLMコールを行うことも許容する。

### **ロギングと評価**

* **ログ:** Core Agentの思考ループ全体を追跡可能な、詳細なログを取得する。  
* **内容:** プロンプト、モデル、主要なI/Oデータに加え、デバッグのための任意情報も記録する。  
* **評価:** 直接的なパフォーマンス評価は困難なため、まずはログの「可観測性」を重視する。

## **2\. 主要コンポーネントの設計詳細**

### **ワークフローの「粒度」と実装方針**

* **基本構造:** 各ワークフローは、自身の定義やメタデータを含むマニフェストファイルと、エントリーポイントとなる単一の非同期実行関数を持つ。  
* **内部実装の自由度:** エントリーポイント関数の内部実装は、各ワークフローの裁量に委ねられる。単純なユーティリティ関数を呼び出すだけのものから、複数の内部メソッドやクラスで構成される複雑なロジックを持つものまで、自由に設計できる。  
* **プロジェクト構成:** ソースコードの管理容易性を高めるため、「1ワークフロー＝1ディレクトリ」の構成を推奨する。

### **イベントキューの優先度制御**

* **方針:** **優先度付きキューを採用する。**  
* **詳細:** イベント（ワークフロー実行リクエスト）には「高」「低」などの優先度を付与できるようにする。これにより、ユーザーからの直接のリクエストのような即時性が求められる処理を、Pondの整理のようなバックグラウンド処理よりも優先して実行できる。  
* **補足:** 思考ループは常時稼働しているため、低優先度タスクが長期間実行されない「飢餓状態」は発生しにくいと考えられ、現時点では複雑な対策は不要とする。

### **A-0: PROCESS\_USER\_REQUESTの初期設計**

* **方針:** **LLMによる意図分類を基本戦略とする。**  
* **前提:** このワークフローが受け取るリクエストは、完全に自由な自然言語ではなく、フロントエンドのクライアントAIによってある程度解釈・整形された、明確な意図を持つリクエストである。  
* **処理フロー:** 受け取ったリクエストをLLMに渡し、後続で実行すべきワークフロー（例：A-1: INGEST\_INPUT, A-4: DEFINE\_SYSTEM\_RULEなど）を判断させ、そのワークフローをイベントキューに追加する。  
* **補足:** この処理は非同期で行われ、クライアントAIは応答を待たないため、LLMのコールによる処理時間の増加は許容する。

## **3\. 次のステップ**

以上の方針に基づき、実装メモに記載の「Proof of Concept (PoC) 開発計画案」に着手します。